[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Remote Sensing Learning Diary",
    "section": "",
    "text": "Julia Pieza Learning Diary\nHello, I’m Julia and this is my CASA0025 Remote Sensing Learning Diary. I’m currently completing the MSc in Urban Spatial Science at UCL whilst also working as a Senior Research and Intelligence officer at Brent Council.",
    "crumbs": [
      "Julia Pieza Learning Diary"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  About me",
    "section": "",
    "text": "After graduating with a History & Politics degree I began working at Brent first completing the NGDP Graduate Scheme and then joining the Data & Insight team.\nMy journey with GIS started at Brent where as an analyst I got the opportunity to learn how to work with geospatial data. Since then I’ve enjoyed the ability to work data analysis projects that help frontline services operate and make a difference to the lives of local residents.\nAt the moment I’m exploring the uses satellite data has in local government, for example addressing challenges like climate change the risks that more extreme weather events pose to urban settings.\nI’m looking forward to sharing my learning throughout this module and being able to share my thoughts on new ways of utilising remotely sensed data to make a difference on a local level.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>About me</span>"
    ]
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "2  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever.\n\n1 + 1\n\n[1] 2",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Summary</span>"
    ]
  },
  {
    "objectID": "week_1.html",
    "href": "week_1.html",
    "title": "3  Week 1: What is Remote Sensing?",
    "section": "",
    "text": "3.1 Summary\nIn week 1 we were introduced to the basic concepts of Remote Sensing which I’ll cover briefly below.\nTo start with some definitions:",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Week 1: What is Remote Sensing?</span>"
    ]
  },
  {
    "objectID": "week_1.html#electromagnetic-waves",
    "href": "week_1.html#electromagnetic-waves",
    "title": "3  Week 1: What is Remote Sensing?",
    "section": "3.2 Electromagnetic Waves",
    "text": "3.2 Electromagnetic Waves\nThe electromagnetic spectrum is essentially the energy that makes remote sensing work.\nAll matter that is above absolute zero temperatures (-273.15°C) radiates EM energy due to molecules moving against one another, and there are several complex processes which can change how much EM energy is radiated, such as temperature. Essentially all natural objects receive and re-emit energy, and we can measure and use this data to identify the material the light is reflecting off of such as vegetation.\n\n\n\nElectromagnetic Spectrum, Source: Wikipedia\n\n\nSource: Wikipedia\n\n3.2.1 Active and Passive Sensors\n\n\n\nSensors, Source: Wikipedia\n\n\nPassive sensing refers to using an external source of EM energy to operate. Commonly the EM energy emitted by the Sun is used to measure the reflection and absorption of light by objects and this data is collected by Satellites which produce images of the Earth.\nFor passive sensors it is important to remember that weather such as clouds or particles in the atmosphere can interfere with the EM energy and cause scattering which can interfere with the image produced. One example of this is Rayleigh scattering where nitrogen and oxygen particles in the air interact with the Sun’s emitted EM waves to create the sunset effect.\nWays in which this can be corrected will be expanded upon in Week 3.\nActive sensors rely on a source of EM to emit and receive electromagnetic waves and measure the backscatter of said wave. For example LiDAR emits rapid laser pulses to collect information about the object or surface based on the return time of the laser pulse.\nAs such active sensors such as Synthetic Aperture Radar (SAR) sends electromagnetic waves that are not on the light spectrum to the Earth which are not interfered with by clouds or atmospheric particles allowing the sensor to capture information at night.\nWe can also think about it in simpler terms, the cameras that exist on our mobile phones are light sensors, allowing us to take images of the environment around us without necessarily making physical contact with it.\n\n\n3.2.2 Resolutions\nThere are 4 resolutions in remote sensed imagery.\n\n\n\n\n\n\n\n\nResolution\nDefinition\nUse\n\n\n\n\nSpatial\nThe size of each pixel in an image corresponds to an area of the Earth’s surface, e.g. one pixel can correspond to as little as a few centimetres (high resolution) to 10km.\nImages of the Earth can be used to detect objects such as buildings. A high spatial resolution allows us to see more detail.\n\n\nSpectral\nSenors which can distinguish between more closely spaced waves are said to measure more Bands of imagery i.e. more wavelengths.\nA high spectral resolution allows us to identify particular types of minerals, vegetation or other features because each object has a unique spectral signature.\n\n\nTemporal\nThe time it takes for a satellite to make an orbit and end at the same observation area. Satellites can have orbits as short as 1 day, or much longer.\nAllows us to see change over time for a particular area of observation.\n\n\nRadiometric\nInformation in each pixel of the image, measured by the number of bits. A 4-bit image indicates there are 16 digital values (grayscale shades) in an image. The more bits the more subtle information can be discerned from the image.\nCan create really detailed images when being able to detect very slight differences in energy, can detect very subtle changes in environments or land use.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Week 1: What is Remote Sensing?</span>"
    ]
  },
  {
    "objectID": "week_1.html#sensors",
    "href": "week_1.html#sensors",
    "title": "3  Week 1: What is Remote Sensing?",
    "section": "4.2 Sensors",
    "text": "4.2 Sensors\n\n4.2.1 Active and Passive Sensors\n\n\n\nSensors, Source: Wikipedia\n\n\nPassive sensing refers to using an external source of EM energy to operate. Commonly the EM energy emitted by the Sun is used to measure the reflection and absorption of light by objects and this data is collected by Satellites which produce images of the Earth.\nFor passive sensors it is important to remember that weather such as clouds or particles in the atmosphere can interfere with the EM energy and cause scattering which can interfere with the image produced. One example of this is Rayleigh scattering where nitrogen and oxygen particles in the air interact with the Sun’s emitted EM waves to create the sunset effect.\nWays in which this can be corrected will be expanded upon in Week 3.\nActive sensors rely on a source of EM to emit and receive electromagnetic waves and measure the backscatter of said wave. For example LiDAR emits rapid laser pulses to collect information about the object or surface based on the return time of the laser pulse.\nAs such active sensors such as Synthetic Aperture Radar (SAR) sends electromagnetic waves that are not on the light spectrum to the Earth which are not interfered with by clouds or atmospheric particles allowing the sensor to capture information at night.\nWe can also think about it in simpler terms, the cameras that exist on our mobile phones are light sensors, allowing us to take images of the environment around us without necessarily making physical contact with it.\n\n\n4.2.2 Resolutions\nThere are 4 resolutions in remote sensed imagery.\n\n\n\n\n\n\n\n\nResolution\nDefinition\nUse\n\n\n\n\nSpatial\nThe size of each pixel in an image corresponds to an area of the Earth’s surface, e.g. one pixel can correspond to as little as a few centimetres (high resolution) to 10km.\nImages of the Earth can be used to detect objects such as buildings. A high spatial resolution allows us to see more detail.\n\n\nSpectral\nSenors which can distinguish between more closely spaced waves are said to measure more Bands of imagery i.e. more wavelengths.\nA high spectral resolution allows us to identify particular types of minerals, vegetation or other features because each object has a unique spectral signature.\n\n\nTemporal\nThe time it takes for a satellite to make an orbit and end at the same observation area. Satellites can have orbits as short as 1 day, or much longer.\nAllows us to see change over time for a particular area of observation.\n\n\nRadiometric\nInformation in each pixel of the image, measured by the number of bits. A 4-bit image indicates there are 16 digital values (grayscale shades) in an image. The more bits the more subtle information can be discerned from the image.\nCan create really detailed images when being able to detect very slight differences in energy, can detect very subtle changes in environments or land use.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Week 1: What is Remote Sensing?</span>"
    ]
  },
  {
    "objectID": "week_1.html#spectral-signatures",
    "href": "week_1.html#spectral-signatures",
    "title": "3  Week 1: What is Remote Sensing?",
    "section": "3.3 Spectral signatures",
    "text": "3.3 Spectral signatures\nDifferent surfaces such as concrete or grassland will reflect EM waves in different ways, creating unique ‘signatures’ that help us identify the type of surface. These signatures reflect various characteristics such as differences between dry and moist ground.\nFor example vegetation tends to absorb visible light (blue and red light specifically used for photosynthesis) and reflects near-infrared energy which can be captured and summarised in a chart. The health of vegetation can be measured in this way as unhealthy plants with less chlorophyll will reflect differently to healthy plants.\n\n\n\nSpectral signatures, Source:NASA",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Week 1: What is Remote Sensing?</span>"
    ]
  },
  {
    "objectID": "week_1.html#open-source-data---landsat-and-sentinel",
    "href": "week_1.html#open-source-data---landsat-and-sentinel",
    "title": "3  Week 1: What is Remote Sensing?",
    "section": "5.1 Open source data - Landsat and Sentinel",
    "text": "5.1 Open source data - Landsat and Sentinel\nThis week we started working with some open satellite data from the Sentinel and Landsat satellites. Sentinel satellites are run by the Copernicus Programme at the European Space Agency and provide high spatial resolution imagery (10-60m per pixel).\nThe Landsat program started by NASA and the US Geological Survey in 1972 has provided imagery across the world.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Week 1: What is Remote Sensing?</span>"
    ]
  },
  {
    "objectID": "week_1.html#snap",
    "href": "week_1.html#snap",
    "title": "3  Week 1: What is Remote Sensing?",
    "section": "5.2 SNAP",
    "text": "5.2 SNAP\nDuring the practical I used SNAP to interact with Sentinel satellite imagery learning how to render these in true colour (RGB) and extract statistics from the data such as the nature of vegetation, e.g. whether the soil is wet or dry.\n\n\n\nGdansk, Source:Sentinel2b\n\n\nI started the practical by looking at recent satellite imagery of Gdansk in January 2026 where large snowfall was reflected in the scatter plot I produced. In order to compute this using the near-infared and green light that plant matter reflects I had to understand the RGB bands used to produce the scatter plot from B4 - B8. In the image for Gdansk and the surrounding areas we can see a lot of wet bare soil which makes sense. \n\n\n\nGdansk SNAP scatter plot, Source: Sentinel2b\n\n\n\n5.2.1 Scatter plot\nThe scatter plot above shows the Band 4 (x axis) and Band 8 (y axis), which are the red and near-infrared bands, so here the lower values of Band 8 and Band 4 are indicating wet bare soil which makes sense given the winter period.\n\n\n5.2.2 Tasseled Cap Transformation\nThe Tasseled Cap Transformation is a method used to analyse the spectral data from multiple bands into a standardised image which incorporates information about surface brightness, vegetation greenness and moisture content.\nBrightness is associated with bare soil or manmade surface helping to identify urban areas. Greeness is associated with green vegetation and wetness with moisture.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Week 1: What is Remote Sensing?</span>"
    ]
  },
  {
    "objectID": "week_1.html#open-source-data---sentinel-and-landsat",
    "href": "week_1.html#open-source-data---sentinel-and-landsat",
    "title": "3  Week 1: What is Remote Sensing?",
    "section": "5.1 Open source data - Sentinel and Landsat",
    "text": "5.1 Open source data - Sentinel and Landsat\nThis week we started working with some open satellite data from the Sentinel and Landsat satellites. Sentinel satellites are run by the Copernicus Programme at the European Space Agency and provide high spatial resolution imagery, 10m, 20, and 60m per pixel resolution depending on the Band used.\nThe Landsat program started by NASA and the US Geological Survey in 1972 has provided imagery across the world. The latest operational Landsat satellites are Landsat 8 and 9 providing 15m, 30m and 100m resolution depending on the Band used.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Week 1: What is Remote Sensing?</span>"
    ]
  },
  {
    "objectID": "week_1.html#snap-case-study-gdansk",
    "href": "week_1.html#snap-case-study-gdansk",
    "title": "3  Week 1: What is Remote Sensing?",
    "section": "5.2 SNAP Case study: Gdansk",
    "text": "5.2 SNAP Case study: Gdansk\nDuring the practical I used SNAP to interact with Sentinel satellite imagery for the Polish city of Gdansk, learning how to render these in true colour (RGB) and extract statistics from the data such as the nature of vegetation, e.g. whether the soil is wet or dry.\n\n\n\nGdansk, Source:Sentinel2b\n\n\n\n5.2.1 Scatter plot\nI started the practical by looking at recent satellite imagery of Gdansk in January 2026 where large snowfall was reflected in the scatter plot I produced. In order to compute this using the near-infrared and green light that plant matter reflects I had to understand the RGB bands used to produce the scatter plot from B4 - B8. In the image for Gdansk and the surrounding areas we can see a lot of wet bare soil which makes sense. \n\n\n\nGdansk SNAP scatter plot, Source: Sentinel2b\n\n\nThe scatter plot above shows the Band 4 (x axis) and Band 8 (y axis), which are the red and near-infrared bands, so here the lower values of Band 8 and Band 4 are indicating wet bare soil which makes sense given the winter period.\n\n\n5.2.2 Tasseled Cap Transformation\nThe Tasseled Cap Transformation is a method used to analyse the spectral data from multiple bands into a standardised image which incorporates information about surface brightness, vegetation greenness and moisture content.\nTo start this process I managed to clip the city boundaries for my raster image importing a shapefile into SNAP and masking it.\n\n\n\nGdansk Clipped SNAP, Source: Sentinel2b\n\n\nI struggled with following the practical and computing the brightness, greenness and wetness bands in SNAP but managed to produce an image attempting to represent the Tasseled Cap function which is a part of Principal Component analysis. Perhaps due to the presence of snow the result is being distorted somehow, but more likely that I computed this image wrong.\nBrightness is associated with bare soil or manmade surfaces helping to identify urban areas. Greeness is associated with green vegetation and wetness with moisture. The green pictured below is correctly identifying the large forest area in the northwest of the clipped boundary. In general there is a lot of vegetation across the city and we cannot see any water bodies as the sea has been clipped out.\nWhat is displayed in pink usually shows man-made surface like concrete and generally reflects built up areas. This accurately reflects the airport in the west of the map, and areas of the city centre, but I would have expected to see more of this around the city centre and it is picking up some bare soil fields in the eastern part of the map.\nI was also expecting the outer fields to show up more brightly given the presence of snow as visible in the image above.\n\n\n\nGdansk TCT, Source: Sentinel2b\n\n\nTo check this further I computed a false composite image using Bands B8, B4 and B3 to check how the near-infrared reflecting plant matter shows up. This does largely match the PCA tasseled cap transformation above with the greenness and the near-infrared reflection captured in red matching well. However I assume due to the presence of snow around the fields in the eastern part of the map is mostly bare soil which is why it appears pink in the PCA and white in the false composite image.\n\n\n\nGdansk False Colour, Source: Sentinel2b\n\n\n\n\n5.2.3 R-Studio application",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Week 1: What is Remote Sensing?</span>"
    ]
  },
  {
    "objectID": "week_1.html#reflections",
    "href": "week_1.html#reflections",
    "title": "3  Week 1: What is Remote Sensing?",
    "section": "3.5 Reflections",
    "text": "3.5 Reflections\nI spent some time reading ahead for the upcoming weeks and was really interested to discover that both multispectral and SAR imagery can be combined to extract information about the natural and urban environments across the world. I found the visual explanation of how this can be done from (Schulte to Bühne and Pettorelli 2018) to be a good introduction and I enjoyed reading about the various examples of environmental monitoring. One of these was outlined by (Ban 2003) exploring how to classify crops such as wheat and corn under good and bad growth conditions to demonstrate how combining Landsat data with SAR gave them the most accurate classification of crop health. I can imagine how valuable this data is during unprecedented weather events that can exacerbate food shortages in vulnerable regions.\nPersonally, working at a Local Council I would be interested to read more about the urban applications of these techniques for monitoring smaller areas of vegetation such as urban farms, or looking at the impact to infrastructure under extreme weather events. Combined with studies of how environmental changes impact citizens and their health outcomes would provide an insightful avenue for using satellite data alongside geodemographic data.\nAs I was looking at various research which utilised satellite imagery around the Gdansk area I found an article (Tysiac, Dąbal, and Widerski 2026) which used multispectral imagery and LiDAR technology for heritage mapping purposes. As an ex-history graduate this grabbed my interest and I found that high resolution imagery (1m), historical maps and machine learning classification to perform analysis in Google Earth Engine to attempt to digitally locate the remnants of a fortification from the 17th century called Gdanska Glowa.\n\n\n\n\nBan, Yifang. 2003. “Synergy of Multitemporal ERS-1 SAR and Landsat TM Data for Classification of Agricultural Crops.” Canadian Journal of Remote Sensing 29 (4): 518–26. https://doi.org/10.5589/m03-014.\n\n\nSchulte to Bühne, Henrike, and Nathalie Pettorelli. 2018. “Better Together: Integrating and Fusing Multispectral and Radar Satellite Imagery to Inform Biodiversity Monitoring, Ecological Research and Conservation Science.” Methods in Ecology and Evolution 9 (4): 849–65. https://doi.org/10.1111/2041-210X.12942.\n\n\nTysiac, Pawel, Joanna Dąbal, and Tadeusz Widerski. 2026. “Multispectral Data and LiDAR for Enhanced Georeferencing of Gdanska Glowa’s 17th-Century Fortifications.” Archaeometry: Bulletin of the Research Laboratory for Archaeology and the History of Art, Oxford University 68 (1): 94–106. https://doi.org/10.1111/arcm.70032.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Week 1: What is Remote Sensing?</span>"
    ]
  },
  {
    "objectID": "week_1.html#summary",
    "href": "week_1.html#summary",
    "title": "3  Week 1: What is Remote Sensing?",
    "section": "",
    "text": "Remote sensing is the collection of data about the Earth from the atmosphere with various technologies that utilise electromagnetic (EM) waves.\nElectromagnetic waves are sources of EM energy used in remote sensing can come from sources like the Sun, or sensors such as LiDAR sending out their own light from a laser and then measuring the the return time for those laser pulses to identify information about the surface of the Earth.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Week 1: What is Remote Sensing?</span>"
    ]
  },
  {
    "objectID": "week_1.html#applications",
    "href": "week_1.html#applications",
    "title": "3  Week 1: What is Remote Sensing?",
    "section": "3.4 Applications",
    "text": "3.4 Applications\n\n3.4.1 Open Source Data - Sentinel and Landsat\nThis week we started working with some open satellite data from the Sentinel and Landsat satellites. Sentinel satellites are run by the Copernicus Programme at the European Space Agency and provide high spatial resolution imagery, 10m, 20, and 60m per pixel resolution depending on the Band used.\nThe Landsat program started by NASA and the US Geological Survey in 1972 has provided imagery across the world. The latest operational Landsat satellites are Landsat 8 and 9 providing 15m, 30m and 100m resolution depending on the Band used.\n\n\n3.4.2 SNAP Case study: Gdansk\nDuring the practical I used SNAP to interact with Sentinel satellite imagery for the Polish city of Gdansk, learning how to render these in true colour (RGB) and extract statistics from the data such as the nature of vegetation, e.g. whether the soil is wet or dry.\n\n\n\nGdansk, Source:Sentinel2b\n\n\n\n\n3.4.3 Scatter plot\nI started the practical by looking at recent satellite imagery of Gdansk in January 2026 where large snowfall was reflected in the scatter plot I produced. In order to compute this using the near-infrared and green light that plant matter reflects I had to understand the RGB bands used to produce the scatter plot from B4 - B8. In the image for Gdansk and the surrounding areas we can see a lot of wet bare soil which makes sense. \n\n\n\nGdansk SNAP scatter plot, Source: Sentinel2b\n\n\nThe scatter plot above shows the Band 4 (x axis) and Band 8 (y axis), which are the red and near-infrared bands, so here the lower values of Band 8 and Band 4 are indicating wet bare soil which makes sense given the winter period.\n\n\n3.4.4 Tasseled Cap Transformation\nThe Tasseled Cap Transformation is a method used to analyse the spectral data from multiple bands into a standardised image which incorporates information about surface brightness, vegetation greenness and moisture content.\nTo start this process I managed to clip the city boundaries for my raster image importing a shapefile into SNAP and masking it.\n\n\n\nGdansk Clipped SNAP, Source: Sentinel2b\n\n\nI struggled with following the practical and computing the brightness, greenness and wetness bands in SNAP but managed to produce an image attempting to represent the Tasseled Cap function which is a part of Principal Component analysis. Perhaps due to the presence of snow the result is being distorted somehow, but more likely that I computed this image wrong.\nBrightness is associated with bare soil or manmade surfaces helping to identify urban areas. Greeness is associated with green vegetation and wetness with moisture. The green pictured below is correctly identifying the large forest area in the northwest of the clipped boundary. In general there is a lot of vegetation across the city and we cannot see any water bodies as the sea has been clipped out.\nWhat is displayed in pink usually shows man-made surface like concrete and generally reflects built up areas. This accurately reflects the airport in the west of the map, and areas of the city centre, but I would have expected to see more of this around the city centre and it is picking up some bare soil fields in the eastern part of the map.\nI was also expecting the outer fields to show up more brightly given the presence of snow as visible in the image above.\n\n\n\nGdansk TCT, Source: Sentinel2b\n\n\nTo check this further I computed a false composite image using Bands B8, B4 and B3 to check how the near-infrared reflecting plant matter shows up. This does largely match the PCA tasseled cap transformation above with the greenness and the near-infrared reflection captured in red matching well. However I assume due to the presence of snow around the fields in the eastern part of the map is mostly bare soil which is why it appears pink in the PCA and white in the false composite image.\n\n\n\nGdansk False Colour, Source: Sentinel2b\n\n\nUnfortunately I was unable to compute the selected points of interest using SNAP as it simply took too long to export into a GeoTiff file. I did not manage to complete the R portion of this practical but I hope that in future weeks I can manage to do this.\nDespite this, the initial experimentation with SNAP allowed me to start to understand how multispectral sensors the Bands they use can be manipulated to produce interesting images to get a better interpretation of the vegetation and urban areas across the city.\nUltimately, I think using data from January wasn’t a great choice given the impact of snow but it definitely made me realise just how much goes into selecting appropriate satellite imagery given that atmospheric events like clouds, fog, snow can alter the usefulness of the images.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Week 1: What is Remote Sensing?</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Ban, Yifang. 2003. “Synergy of Multitemporal ERS-1\nSAR and Landsat TM Data for Classification of\nAgricultural Crops.” Canadian Journal of Remote Sensing\n29 (4): 518–26. https://doi.org/10.5589/m03-014.\n\n\nSchulte to Bühne, Henrike, and Nathalie Pettorelli. 2018. “Better\nTogether: Integrating and Fusing Multispectral and Radar\nSatellite Imagery to Inform Biodiversity Monitoring, Ecological Research\nand Conservation Science.” Methods in Ecology and\nEvolution 9 (4): 849–65. https://doi.org/10.1111/2041-210X.12942.\n\n\nTysiac, Pawel, Joanna Dąbal, and Tadeusz Widerski. 2026.\n“Multispectral Data and LiDAR for Enhanced\nGeoreferencing of Gdanska Glowa’s 17th-Century Fortifications.”\nArchaeometry: Bulletin of the Research Laboratory for Archaeology\nand the History of Art, Oxford University 68 (1): 94–106. https://doi.org/10.1111/arcm.70032.",
    "crumbs": [
      "References"
    ]
  }
]