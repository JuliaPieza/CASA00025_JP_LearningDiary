[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Remote Sensing Learning Diary",
    "section": "",
    "text": "Julia Pieza Learning Diary\nHello, I’m Julia and this is my CASA0025 Remote Sensing Learning Diary. I’m currently completing the MSc in Urban Spatial Science at UCL whilst also working as a Senior Research and Intelligence officer at Brent Council.",
    "crumbs": [
      "Julia Pieza Learning Diary"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  About me",
    "section": "",
    "text": "After graduating with a History & Politics degree I began working at Brent first completing the NGDP Graduate Scheme and then joining the Data & Insight team.\nMy journey with GIS started at Brent where as an analyst I got the opportunity to learn how to work with geospatial data. Since then I’ve enjoyed the ability to work data analysis projects that help frontline services operate and make a difference to the lives of local residents.\nAt the moment I’m exploring the uses satellite data has in local government, for example addressing challenges like climate change the risks that more extreme weather events pose to urban settings.\nI’m looking forward to sharing my learning throughout this module and being able to share my thoughts on new ways of utilising remotely sensed data to make a difference on a local level.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>About me</span>"
    ]
  },
  {
    "objectID": "week_1.html",
    "href": "week_1.html",
    "title": "2  Week 1: What is Remote Sensing?",
    "section": "",
    "text": "2.1 Summary\nIn week 1 we were introduced to the basic concepts of Remote Sensing which I’ll cover briefly below.\nTo start with some definitions:",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Week 1: What is Remote Sensing?</span>"
    ]
  },
  {
    "objectID": "week_1.html#summary",
    "href": "week_1.html#summary",
    "title": "2  Week 1: What is Remote Sensing?",
    "section": "",
    "text": "Remote sensing is the collection of data about the Earth from the atmosphere with various technologies that utilise electromagnetic (EM) waves.\nElectromagnetic waves are sources of EM energy used in remote sensing can come from sources like the Sun, or sensors such as LiDAR sending out their own light and then measuring the the return time for the light pulses to identify information about the surface of the Earth.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Week 1: What is Remote Sensing?</span>"
    ]
  },
  {
    "objectID": "week_1.html#electromagnetic-waves",
    "href": "week_1.html#electromagnetic-waves",
    "title": "2  Week 1: What is Remote Sensing?",
    "section": "2.2 Electromagnetic Waves",
    "text": "2.2 Electromagnetic Waves\nThe electromagnetic spectrum is essentially the energy that makes remote sensing work.\nAll matter that is above absolute zero temperatures (-273.15°C) radiates EM energy due to molecules moving against one another, and there are several complex processes which can change how much EM energy is radiated, such as temperature. Essentially all natural objects receive and re-emit energy, and we can measure and use this data to identify the material the light is reflecting off of such as vegetation.\n\n\n\nElectromagnetic Spectrum, Source: Wikipedia\n\n\nSource: Wikipedia\n\n2.2.1 Active and Passive Sensors\n\n\n\nSensors, Source: Wikipedia\n\n\nPassive sensing refers to using an external source of EM energy to operate. Commonly the EM energy emitted by the Sun is used to measure the reflection and absorption of light by objects and this data is collected by Satellites which produce images of the Earth.\nFor passive sensors it is important to remember that weather such as clouds or particles in the atmosphere can interfere with the EM energy and cause scattering which can interfere with the image produced. One example of this is Rayleigh scattering where nitrogen and oxygen particles in the air interact with the Sun’s emitted EM waves to create the sunset effect.\nWays in which this can be corrected will be expanded upon in Week 3.\nActive sensors rely on a source of EM to emit and receive electromagnetic waves and measure the backscatter of said wave. For example LiDAR emits rapid laser pulses to collect information about the object or surface based on the return time of the laser pulse.\nAs such active sensors such as Synthetic Aperture Radar (SAR) sends electromagnetic waves that are not on the light spectrum to the Earth which are not interfered with by clouds or atmospheric particles allowing the sensor to capture information at night.\nWe can also think about it in simpler terms, the cameras that exist on our mobile phones are light sensors, allowing us to take images of the environment around us without necessarily making physical contact with it.\n\n\n2.2.2 Resolutions\nThere are 4 resolutions in remote sensed imagery.\n\n\n\n\n\n\n\n\nResolution\nDefinition\nUse\n\n\n\n\nSpatial\nThe size of each pixel in an image corresponds to an area of the Earth’s surface, e.g. one pixel can correspond to as little as a few centimetres (high resolution) to 10km.\nImages of the Earth can be used to detect objects such as buildings. A high spatial resolution allows us to see more detail.\n\n\nSpectral\nSenors which can distinguish between more closely spaced waves are said to measure more Bands of imagery i.e. more wavelengths.\nA high spectral resolution allows us to identify particular types of minerals, vegetation or other features because each object has a unique spectral signature.\n\n\nTemporal\nThe time it takes for a satellite to make an orbit and end at the same observation area. Satellites can have orbits as short as 1 day, or much longer.\nAllows us to see change over time for a particular area of observation.\n\n\nRadiometric\nInformation in each pixel of the image, measured by the number of bits. A 4-bit image indicates there are 16 digital values (grayscale shades) in an image. The more bits the more subtle information can be discerned from the image.\nCan create really detailed images when being able to detect very slight differences in energy, can detect very subtle changes in environments or land use.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Week 1: What is Remote Sensing?</span>"
    ]
  },
  {
    "objectID": "week_1.html#spectral-signatures",
    "href": "week_1.html#spectral-signatures",
    "title": "2  Week 1: What is Remote Sensing?",
    "section": "2.3 Spectral signatures",
    "text": "2.3 Spectral signatures\nDifferent surfaces such as concrete or grassland will reflect EM waves in different ways, creating unique ‘signatures’ that help us identify the type of surface. These signatures reflect various characteristics such as differences between dry and moist ground.\nFor example vegetation tends to absorb visible light (blue and red light specifically used for photosynthesis) and reflects near-infrared energy which can be captured and summarised in a chart. The health of vegetation can be measured in this way as unhealthy plants with less chlorophyll will reflect differently to healthy plants.\n\n\n\nSpectral signatures, Source:NASA",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Week 1: What is Remote Sensing?</span>"
    ]
  },
  {
    "objectID": "week_1.html#applications",
    "href": "week_1.html#applications",
    "title": "2  Week 1: What is Remote Sensing?",
    "section": "2.4 Applications",
    "text": "2.4 Applications\n\n2.4.1 Open Source Data - Sentinel and Landsat\nThis week we started working with some open satellite data from the Sentinel and Landsat satellites. Sentinel satellites are run by the Copernicus Programme at the European Space Agency and provide high spatial resolution imagery, 10m, 20, and 60m per pixel resolution depending on the Band used.\nThe Landsat program started by NASA and the US Geological Survey in 1972 has provided imagery across the world. The latest operational Landsat satellites are Landsat 8 and 9 providing 15m, 30m and 100m resolution depending on the Band used.\n\n\n2.4.2 SNAP Case study: Gdansk\nDuring the practical I used SNAP to interact with Sentinel satellite imagery for the Polish city of Gdansk, learning how to render these in true colour (RGB) and extract statistics from the data such as the nature of vegetation, e.g. whether the soil is wet or dry.\n\n\n\nGdansk, Source:Sentinel2b\n\n\n\n\n2.4.3 Scatter plot\nI started the practical by looking at recent satellite imagery of Gdansk in January 2026 where large snowfall was reflected in the scatter plot I produced. In order to compute this using the near-infrared and green light that plant matter reflects I had to understand the RGB bands used to produce the scatter plot from B4 - B8. In the image for Gdansk and the surrounding areas we can see a lot of wet bare soil which makes sense. \n\n\n\nGdansk SNAP scatter plot, Source: Sentinel2b\n\n\nThe scatter plot above shows the Band 4 (x axis) and Band 8 (y axis), which are the red and near-infrared bands, so here the lower values of Band 8 and Band 4 are indicating wet bare soil which makes sense given the winter period.\n\n\n2.4.4 Tasseled Cap Transformation\nThe Tasseled Cap Transformation is a method used to analyse the spectral data from multiple bands into a standardised image which incorporates information about surface brightness, vegetation greenness and moisture content.\nTo start this process I managed to clip the city boundaries for my raster image importing a shapefile into SNAP and masking it.\n\n\n\nGdansk Clipped SNAP, Source: Sentinel2b\n\n\nI struggled with following the practical and computing the brightness, greenness and wetness bands in SNAP but managed to produce an image attempting to represent the Tasseled Cap function which is a part of Principal Component analysis. Perhaps due to the presence of snow the result is being distorted somehow, but more likely that I computed this image wrong.\nBrightness is associated with bare soil or manmade surfaces helping to identify urban areas. Greeness is associated with green vegetation and wetness with moisture. The green pictured below is correctly identifying the large forest area in the northwest of the clipped boundary. In general there is a lot of vegetation across the city and we cannot see any water bodies as the sea has been clipped out.\nWhat is displayed in pink usually shows man-made surface like concrete and generally reflects built up areas. This accurately reflects the airport in the west of the map, and areas of the city centre, but I would have expected to see more of this around the city centre and it is picking up some bare soil fields in the eastern part of the map.\n\n\n\nGdansk TCT, Source: Sentinel2b\n\n\nTo check this further I computed a false composite image using Bands B8, B4 and B3 to check how the near-infrared reflecting plant matter shows up. This does largely match the PCA tasseled cap transformation above with the greenness and the near-infrared reflection captured in red matching well. However I assume due to the presence of snow around the fields in the eastern part of the map is mostly bare soil which is why it appears pink in the PCA and white in the false composite image.\n\n\n\nGdansk False Colour, Source: Sentinel2b\n\n\nUnfortunately I was unable to compute the selected points of interest using SNAP as it simply took too long to export into a GeoTiff file. I did not manage to complete the R portion of this practical but I hope that in future weeks I can manage to do this.\nHowever, from the practical using the Cape Town example I can see how plotting the spectral values for various land cover areas can combine several spectral signatures to showcase distinctions between areas of forest or grass. The applications of this in areas of environmental monitoring, or urban planning e.g. looking at spectral signatures of certain chemicals in the atmosphere or in water could help expose illegal polluting activity.\n\n\n\nCape Town Spectral Signatures, Source: CASA0023\n\n\nDespite not being able to compute the points of interest for Gdansk, working with SNAP helped me understand how multispectral sensors the Bands they use can be manipulated to produce interesting images to get a better interpretation of the vegetation and urban areas across the city.\nUltimately, I think using data from January wasn’t a great choice given the impact of snow but it definitely made me realise just how much goes into selecting appropriate satellite imagery given that atmospheric events like clouds, fog, snow can alter the usefulness of the images.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Week 1: What is Remote Sensing?</span>"
    ]
  },
  {
    "objectID": "week_1.html#reflections",
    "href": "week_1.html#reflections",
    "title": "2  Week 1: What is Remote Sensing?",
    "section": "2.5 Reflections",
    "text": "2.5 Reflections\nAlthough it was somewhat difficult to work with SNAP this week I have really enjoyed working with new types of data and getting to understand how remote sensing works.\nI spent some time reading ahead for the upcoming weeks and was really interested to discover that both multispectral and SAR imagery can be combined to extract information about the natural and urban environments across the world. I found the visual explanation of how this can be done from (Schulte to Bühne and Pettorelli 2018) to be a good introduction and I enjoyed reading about the various examples of environmental monitoring. One of these was outlined by (Ban 2003) exploring how to classify crops such as wheat and corn under good and bad growth conditions to demonstrate how combining Landsat data with SAR gave them the most accurate classification of crop health. I can imagine how valuable this data is during unprecedented weather events that can exacerbate food shortages in vulnerable regions.\nPersonally, working at a Local Council I would be interested to read more about the urban applications of these techniques for monitoring smaller areas of vegetation such as urban farms, or looking at the impact to infrastructure under extreme weather events. Combined with studies of how environmental changes impact citizens and their health outcomes would provide an insightful avenue for using satellite data alongside geodemographic data. However, I can also imagine there are obstacles to getting high spectral and spatial resolution imagery due to costs, and the technical requirements to process really detailed spectral signatures.\n\n\n\n\nBan, Yifang. 2003. “Synergy of Multitemporal ERS-1 SAR and Landsat TM Data for Classification of Agricultural Crops.” Canadian Journal of Remote Sensing 29 (4): 518–26. https://doi.org/10.5589/m03-014.\n\n\nSchulte to Bühne, Henrike, and Nathalie Pettorelli. 2018. “Better Together: Integrating and Fusing Multispectral and Radar Satellite Imagery to Inform Biodiversity Monitoring, Ecological Research and Conservation Science.” Methods in Ecology and Evolution 9 (4): 849–65. https://doi.org/10.1111/2041-210X.12942.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Week 1: What is Remote Sensing?</span>"
    ]
  },
  {
    "objectID": "week_2.html",
    "href": "week_2.html",
    "title": "3  Week 2: LiDAR",
    "section": "",
    "text": "3.1 Xaringan Presentation: LiDAR\nThis week we worked on creating Xaringan presentations using R, below you’ll find my short presentation on LiDAR, and specifically the European Space Agency EarthCARE satellite.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Week 2: LiDAR</span>"
    ]
  },
  {
    "objectID": "week_3.html",
    "href": "week_3.html",
    "title": "4  Week 3: Corrections",
    "section": "",
    "text": "4.1 Summary\nIn Week 3 we covered the corrections that are often necessary to make remotely sensed data usable for analysis.\nAlthough most remotely sensed data nowadays comes ‘analysis ready’ it was interesting and useful to understand these concepts in more detail.\nIn this chapter I’ll summarise:\nBefore moving onto the applications where I look at NVDI and Texture analysis in Gdansk and my reflections.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Week 3: Corrections</span>"
    ]
  },
  {
    "objectID": "week_3.html#summary",
    "href": "week_3.html#summary",
    "title": "4  Week 3: Corrections",
    "section": "",
    "text": "Radiative transfer and atmospheric correction\nGeometric distortions and corrections\nOrthorectification/topographic correction\nRadiometric calibration\n\n\n\n4.1.1 Radiative transfer and atmospheric correction\nGoing back to concepts from Week 1 radiative transfer was helpful to recap in the context of understanding why atmospheric correction is needed for remotely sensed data.\nI enjoyed the video from Karen Joyce explaining this concept in an accessible way using the example of emitted sunlight (Top of Atmosphere irradiance) which is reflected off of a surface and into a sensor (also referred to as At Sensor Radiance). However, some light from the sun will end up being scattered in the atmosphere (diffuse irradiance) and will also get recorded by the sensor.\nWhereas, ground scanners measure total radiance i.e. all light reflected off the sun, sensors in the atmosphere or in space will measure At Sensor Radiance. To get an accurate image of the ground the atmospheric component (additive path radiance) needs to be subtracted from the At Sensor Radiance i.e. the sensor produced image.\n\n\n\nAtmospheric correction, Source: ESA\n\n\nThere are several ways to correct for this haze-like effect, this is especially necessary when we want to extract accurate information about the biophysical nature of the image e.g. plant health or temperature as these will get distorted by the light interactions with particles in the atmosphere. The list below is not an exhaustive list of methods but a flavour of what’s available and how it works.\n\n\n\n\n\n\n\n\nCorrection\nMethod\nPros & Cons\n\n\n\n\nDark Object Substraction\nFind the darkest value from the image collected and subtract this value from each pixel. Works on the principle that some dark objects e.g. water bodies will have near zero reflectance, and these values can then be subtracted from all the pixels in the image to remove atmospheric haze.\nPros: relative normalisation to a reference image often not expensive\nCons: there may not be a dark object within an image to normalise to\n\n\nPseudo Invariant Features\nTakes features which do not change in an image e.g. a road or carpark, this will have a temporally stable spectral reflectance and can be used to normalise the imagery using linear regression to remove the atmospheric effects.\nPros: inexpensive if a reference image has a PIF\nCons: if there is no PIF feature it can be unreliable, assumes reference image atmospheric distortion will be similar across time\n\n\nFLAASH (Fast line of sight atmospheric analysis)\nRemoves atmospheric effects by modelling the atmosphere using a technique called MODTRAN which simulates the atmospheric path and enables the estimation of light scattering between the ground and sensor.\nIt requires more detailed information about the sensor and is a more expensive tool to use, however the calculations based on physics enable precise correction.\nPros: an absolute atmospheric correction is usually more precise\nCons: requires more detailed atmospheric data and often expensive models to model atmospheric condition at the time of the image taken\n\n\n\n\n\n4.1.2 Geometric distortion and corrections: \nApart from light there are other ways in which the way the sensor collects an image can result in some need for correction, these are geometric distortions such as:\n\nView angle - whether the sensor collects data straight down or at a Nadir or at an angle\nTopography - hills vs flatlands\nRotation of the earth - from satellite data, depending on the path of flight of the satellite\nOr things like wind if data is collected from a plane\n\nThe most common way to correct for geometric distortions is by having Ground Control Points (GCPs) to match existing features from a reference picture. Examples of this are:\n\nLocal maps \nGPS data from another device \nOr another satellite image\n\nHere we look for points that wouldn’t have changed, potentially natural features like rivers although these can change so sometimes man-made features can work better.\n\n\n4.1.3 Orthorectification /topographic correction\nGeorectification refers to adding coordinates to an image and orthorectification refers to removing the distortions to make an image at a nadir angle i.e. straight down. \nThis is a subset of geometric correction.\nIn order to make an orthorectified image the elevation needs to be known, as well as GCPs which then allow a correction algorithm to transform the raw data into an orthorectified image. There are various algorithms to do this often depending on the sensor, image resolution and the desired level of accuracy.\n\n\n4.1.4 Radiometric calibration\nThis is the process of converting the image brightness captured as Digital Numbers by sensors into spectral radiance.\nDigital Numbers refer to the brightness captured in a remotely sensed image, but they have no units.\nSpectral radiance is the amount of light within a band from a sensor, measured in Watts, per metre squared, per steradian (angle of view), per nanometre (wavelenght).\nThis is necessary when collecting images across time, which will be influenced by atmospheric and geometric distortions so to compare these more accurately we need to calibrate the pixel values using information about the sensor (e.g. how it was calibrated).",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Week 3: Corrections</span>"
    ]
  },
  {
    "objectID": "week_3.html#applications",
    "href": "week_3.html#applications",
    "title": "4  Week 3: Corrections",
    "section": "4.2 Applications",
    "text": "4.2 Applications\n\n4.2.1 Image enhancements: NVDI\nUsing a technique called ratioing I was able to calculate the Normalised Difference Vegetation Index (NDVI) which works by comparing near-infrared bands to red light wavelengths to reflect healthy and less healthy vegetation.\n\n\n\nNVDI, Source: GeoPard Agriculture\n\n\nI was able to calculate NDVI by using Landsat 8 images for Gdansk using the following formula and subtracting the near-infrared band (Band 5) from red light wavelength (Band 4), and then dividing by the sum of both.\n\n\n\nGdansk NVDI, Source: Landsat 8\n\n\nThe image above reflects vegetation in August 2025, where we can see dense vegetation across the forest area of Lasy Oliwskie. Nevertheless it is actually more difficult to assess the health of vegetation without more comparison over time as the lower NDVI figures reflect water and built up areas of sparse vegetation, hence for future analysis it might make more sense to subset this area and compare the NDVI for more dense vegetation areas across time to look at plant health. As this imagery is from August 2025 there may be areas where plant health is worse due to heat which last year was between 25-31 degrees Celsius.\n\n\n4.2.2 Filtering\nI was also able to filter the image to show everything above NDVI 0.2, this can be used to mask out vegetation from built up areas which can be useful for further monitoring.\n\n\n\nGdansk NVDI, Source: Landsat 8\n\n\nAs mentioned above there are some caveats with the NDVI index that I wanted to understand more, especially when filtering NDVI and making sense of what increasing by 0.1 meant and whether it was useful for reflecting the health of vegetation.\nI found reading Iglesia Martinez and Labib (2023) helped to this into context, as they focus on Greater Manchester to identify how NDVI values can be “sensitive to certain vegetation types and quantities at different spatial scales”. This means that an change between NDVI 0.2 to 0.3 may be associated with a greater increase in greenspace % compared to an increase from 0.5 to 0.6 and thus may tell us where greening policies can have the highest impact for communities.\nHowever, this also varies depending on the area we’re looking at so their results aren’t necessarily replicable in different cities, so working with NDVI may require first understanding how vegetation types like trees, shurbs and grass affect the index.\n\n\n4.2.3 Texture analysis\nNext I wanted to look at potentially extracting more of the built up areas of the city using the Gray Level Co-occurence Matrix GLCMTextures package to calculate the more ‘jagged’ texture of man-made materials like concrete by comparing variance to the adjacent pixels.\nI played around with the settings and looked at the GLCM_entropy metric to look at low entropy areas such as calm water or smooth surfaces and higher entropy for areas like urban settings.\n\n\n\nGdansk GLCM_Textures, Source: Landsat 8\n\n\nI think another way to improve on this would be to select a smaller neighbourhood to look at textures within the city centre urban area and see if we can identify differences between dense built up areas or industrial areas vs residential areas.\n\n\n4.2.4 Data fusion - PCA\nData fusion was something I was really interested in after reading Schulte to Bühne and Pettorelli (2018) and here it is applied in a slightly simpler sense, by taking the texture produced above as a new Band effectively appending it to our original raster dataset. Using this we can better see the differences between built up and vegetation across Gdansk, although as mentioned in the lecture this where remote sensing becomes more of an art, as there is a lot of room to transform the data in many different ways.\nFollowing on from Week 1, PCA is used to reduce the dimensionality of remotely sensed data, in this week’s practical I combined the texture data with the spectral reflectance Landsat 8 data for Gdansk.\nThis was done to reduce the number of variables in my data helping to enhance my image whilst keeping the key patterns of the dataset e.g. my vegetation vs urban areas divide.\n\n\n\nGdansk PCA Source: Landsat 8\n\n\nIn the image above PCA1 captures most of the variance between the vegetation and more built up areas and can be used by a machine learning algorithm to predict trends and patterns visible in the data.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Week 3: Corrections</span>"
    ]
  },
  {
    "objectID": "week_3.html#reflections",
    "href": "week_3.html#reflections",
    "title": "4  Week 3: Corrections",
    "section": "4.3 Reflections",
    "text": "4.3 Reflections\nI think the analysis I was able to produce could be better to show more distinction between the built-up areas and vegetation but for a first go with texture and raster PCA I am glad it generally worked.\nWorking with texture analysis was useful for separating some of the natural environment from built environment, and I think in the future working with a smaller area could be really useful for my work, for example mapping neighbourhood level green spaces, or underutilised sites and see where in the borough there are opportunities for redevelopment.\nAdditionally, as I was looking at various research which used satellite imagery around the Gdansk area I found an article (Tysiac, Dąbal, and Widerski 2026) which used multispectral imagery and LiDAR technology for heritage mapping purposes. It was interesting to see heritage uses of remote sensing technology to narrow down locations for potential digging sites. In this example the high resolution imagery (1m), historical maps and machine learning classification algorithms were used in Google Earth Engine to digitally locate the remnants of a fortification from the 17th century called Gdanska Glowa.\nI think there is a lot to be gained from mastering the ‘art’ of combining various methods and technologies together for these really specific purposes and I am looking forward to exploring this more with Google Earth Engine. This week also followed nicely on from Week 2 where I did a lot of reading about LiDAR and was excited to find how widely used it can be.\n\n\n\n\nIglesia Martinez, Alex de la, and S. M. Labib. 2023. “Demystifying Normalized Difference Vegetation Index (NDVI) for Greenness Exposure Assessments and Policy Interventions in Urban Greening.” Environmental Research 220: 115155. https://doi.org/https://doi.org/10.1016/j.envres.2022.115155.\n\n\nSchulte to Bühne, Henrike, and Nathalie Pettorelli. 2018. “Better Together: Integrating and Fusing Multispectral and Radar Satellite Imagery to Inform Biodiversity Monitoring, Ecological Research and Conservation Science.” Methods in Ecology and Evolution 9 (4): 849–65. https://doi.org/10.1111/2041-210X.12942.\n\n\nTysiac, Pawel, Joanna Dąbal, and Tadeusz Widerski. 2026. “Multispectral Data and LiDAR for Enhanced Georeferencing of Gdanska Glowa’s 17th-Century Fortifications.” Archaeometry: Bulletin of the Research Laboratory for Archaeology and the History of Art, Oxford University 68 (1): 94–106. https://doi.org/10.1111/arcm.70032.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Week 3: Corrections</span>"
    ]
  },
  {
    "objectID": "week_4.html",
    "href": "week_4.html",
    "title": "5  Week 4: Policy",
    "section": "",
    "text": "5.1 Summary\nIn week 4 we looked at how remotely sensed data has been used in policymaking. For example using NDVI to look at the benefits of greenspace on both mental and physical health, or the impact of urban heat such as the Urban Heat Island effect.\nWe were asked to imagine how a remotely sensed dataset may be incorporated into policymaking at a city, national or international level.\nIn this week I’ll focus on Gdansk and the Gdansk 2030 Plus City Development Strategy, specifically the Green City objective which aims to improve the biodiversity of the city and provide more green spaces to residents.\nAlthough Poland does not have nation wide climate law it is bound by EU legislation to reduce greenhouse gas emissions.\nNevertheless cities in Poland have increasingly chosen to implement their own strategies to ensure preparedness for the effects fo climate change. However the institutions responsible for maintaining the natural environment are often uncoordinated due to different responsibilities sitting with Regional Directors of environmental protection or being the responsibility of Voivodeship-level government.\nThe City Development Strategy Gdansk 2030 Plus aims to help mitigate the climate-related risks due to it’s coastal position and continued development of the city’s infrastructure, by coordinating the policies of several environmental bodies towards key strategic priorities.\nTo begin the process of drafting this strategy over 3 thousand people, and institutions such as universities and businesses were surveyed about their priorities for the City’s development.\nAround 63% of those surveyed identified greenery and biodiversity as their key priority for the city, with policies such as adding 100 hectares of new parks, and 50,000 new trees being some of the most popular. Piotr Krzyszewski (2024)",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Week 4: Policy</span>"
    ]
  },
  {
    "objectID": "week_4.html#summary",
    "href": "week_4.html#summary",
    "title": "5  Week 4: Policy",
    "section": "",
    "text": "5.1.1 Green City policies\n\nPlanting 50,000 trees\nReduction of greenhouse gas CO2 emissions by 30%\nEstablishing a network of green belts along water courses\nImplementation of a Southern Park\n\n\n\n5.1.2 Link to UN Sustainable Development Goals\nThe greening policies backed by a majority of those surveyed also align with broader international climate strategies such as the Sustainable Development Goals.\nIn particular the Gdansk Development Strategy aligns with Goal 15 to “protect, restore and promote use of terrestrial ecosystems, sustainably manage forests, combat desertification, and halt reverse land degredation and halt biodiversity loss”. (DESA (2024))\nFocusing on maintaining the health and biodiversity of existing forests such as Lasy Oliwskie, in addition to planting 50,000 trees, and adding a new Southern Park will help to preserve existing biodiversity and create new protected spaces for natural habitats to develop and thrive. An interesting proposal is to also create a network of green areas and water and increase 15 minute access zones to forests and green areas.\n\n\n\nGdansk Land Use, Source: Gdansk Plus City Development Strategy\n\n\n\n\n\nGdansk Natural Environment, Source: Gdansk Plus City Development Strategy",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Week 4: Policy</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Ban, Yifang. 2003. “Synergy of Multitemporal ERS-1\nSAR and Landsat TM Data for Classification of\nAgricultural Crops.” Canadian Journal of Remote Sensing\n29 (4): 518–26. https://doi.org/10.5589/m03-014.\n\n\nIglesia Martinez, Alex de la, and S. M. Labib. 2023. “Demystifying\nNormalized Difference Vegetation Index (NDVI) for Greenness Exposure\nAssessments and Policy Interventions in Urban Greening.”\nEnvironmental Research 220: 115155. https://doi.org/https://doi.org/10.1016/j.envres.2022.115155.\n\n\nPiotr Krzyszewski, Piotr Borawski, Monika Chabior. 2024. “Gdansk\nDevelopment Programmes 2030.” Gdansk City Hall. https://download.cloudgdansk.pl/gdansk-pl/d/202403227429/gdansk-development-programmes-2030.pdf.\n\n\nSchulte to Bühne, Henrike, and Nathalie Pettorelli. 2018. “Better\nTogether: Integrating and Fusing Multispectral and Radar\nSatellite Imagery to Inform Biodiversity Monitoring, Ecological Research\nand Conservation Science.” Methods in Ecology and\nEvolution 9 (4): 849–65. https://doi.org/10.1111/2041-210X.12942.\n\n\nTysiac, Pawel, Joanna Dąbal, and Tadeusz Widerski. 2026.\n“Multispectral Data and LiDAR for Enhanced\nGeoreferencing of Gdanska Glowa’s 17th-Century Fortifications.”\nArchaeometry: Bulletin of the Research Laboratory for Archaeology\nand the History of Art, Oxford University 68 (1): 94–106. https://doi.org/10.1111/arcm.70032.",
    "crumbs": [
      "References"
    ]
  },
  {
    "objectID": "week_4.html#applications",
    "href": "week_4.html#applications",
    "title": "5  Week 4: Policy",
    "section": "5.2 Applications:",
    "text": "5.2 Applications:\nThere are many opportunities for using remotely sensed data in relation to greening policies, whether its through identifying sites suitable for additional trees, new parks or green corridors, or monitoring progress of such policies in increasing green land cover. I will outline potential applications of NDVI and LULC with references to how these have been used in other studies.\nAs shown above Gdansk has a diverse natural environment, as a coastal city with large forested areas made accessible for residents, a key part of using remotely sensed data would be first to measure the existing health and extent of these green areas.\nThis can be primarily achieved by using the Normalised Difference Vegetation Index (NDVI) which measures the spatial distribution of vegetation. I measured the NDVI for Gdansk in August 2025 based on Landsat 8 data which had a 15-30m resolution in Week 3. This was useful for identifying the presence of green areas but as explored by Iglesia Martinez and Labib (2023) NDVI can be more sensitive to certain types of vegetation such as trees at various buffer levels in their case study of Greater Manchester. Using Sentinel 2 data instead could create a slightly more high resolution picture of this index.\n\n\n\nGdansk NVDI, Source: Landsat 8\n\n\nLooking at NDVI alongside Land Use-Land Cover data from Sentinel 2 could be useful in this exercise, as it was also used by Iglesia Martinez and Labib (2023), who obtained the data from Dennis et al. (2018) at 10m resolution. Using this approach with Gdansk could support monitoring change over time to understand the progress of greening activities. This has been done by looking and LULC data with time-series methods by DU et al. (2010) looking at Landsat images to assess land cover and vegetation change in Xuzhou over 20 years.\nOr as a start it could help to create an even more detailed picture of green spaces within urban environments at a 10m resolution.\nHowever it is important to understand some limitations, even at 10m resolution dense urban settings become harder to distinguish at this pixel size. To look at neighbourhood level greening policies where open space may be scarce we may need to opt for even higher resolutions of 1-5m, but the trade-off here is between the temporal availability and price of this data.\n-studies on the impact of greening policies",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Week 4: Policy</span>"
    ]
  },
  {
    "objectID": "week_4.html#reflections",
    "href": "week_4.html#reflections",
    "title": "5  Week 4: Policy",
    "section": "5.3 Reflections:",
    "text": "5.3 Reflections:\nI found it interesting to look at the City of Gdansk and it’s Development Strategy, knowing that most residents prioritised increasing green spaces in the city led me to think about the possible uses of remotely sensed data to identify areas for greening, or monitor progress in the future.\nI think the combination of NDVI and LULC measures at a high resolution of 10m can provide a good level of detail, and methods like time series can be used to monitor change.\nReading about the advancements in using remotely sensed data for evidence-based policy making was really interesting. I think the summary presented in Kadhim, Mourshed, and Bray (2016) was extremely useful for understanding what is available, the tradeoffs between spatial and temporal resolutions, and the large number of studies cited as examples.\nI used this article as a starting point for understanding the current challenges for working with remotely sensed data to visualise and model dense urban landscapes. As this is an emerging area, most open source satellite data goes up to 10m resolution, but for these urban settings even higher resolutions may be needed.\nI would like to learn more about how to incorporate more machine learning algorithms, time series and regression analysis on remote sensed data so I am looking forward to exploring this more with Google Earth Engine.\n\n\n\n\nDennis, Matthew, David Barlow, Gina Cavan, Penny A. Cook, Anna Gilchrist, John Handley, Philip James, et al. 2018. “Mapping Urban Green Infrastructure: A Novel Landscape-Based Approach to Incorporating Land Use and Land Cover in the Mapping of Human-Dominated Systems.” Land 7 (17). https://doi.org/10.3390/land7010017.\n\n\nDESA, UN. 2024. “The Sustainable Development Goals Report 2024 – June 2024.” United Nations. https://unstats.un.org/sdgs/report/2024/.\n\n\nDU, Peijun, Xingli LI, Wen CAO, Yan LUO, and Huapeng ZHANG. 2010. “Monitoring Urban Land Cover and Vegetation Change by Multi-Temporal Remote Sensing Information.” Mining Science and Technology (China) 20 (6): 922–32. https://doi.org/10.1016/S1674-5264(09)60308-2.\n\n\nIglesia Martinez, Alex de la, and S. M. Labib. 2023. “Demystifying Normalized Difference Vegetation Index (NDVI) for Greenness Exposure Assessments and Policy Interventions in Urban Greening.” Environmental Research 220: 115155. https://doi.org/https://doi.org/10.1016/j.envres.2022.115155.\n\n\nKadhim, Nada, Monjur Mourshed, and Michaela Bray. 2016. “Advances in Remote Sensing Applications for Urban Sustainability.” Euro-Mediterranean Journal for Environmental Integration 1 (1): 7. https://doi.org/10.1007/s41207-016-0007-4.\n\n\nPiotr Krzyszewski, Piotr Borawski, Monika Chabior. 2024. “Gdansk Development Programmes 2030.” Gdansk City Hall. https://download.cloudgdansk.pl/gdansk-pl/d/202403227429/gdansk-development-programmes-2030.pdf.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Week 4: Policy</span>"
    ]
  }
]